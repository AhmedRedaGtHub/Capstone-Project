{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "<img src=\"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width=\"300\" align=\"left\"><font size=\"6.5\"><h1 align=\"center\">Applied Data Science Capstone</font>", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "<h3 align=\"center\"><font size=\"5\">This notebook is intended for the final course in IBM Data Science Professional Certificate.</font>\n<hr style=\"border: dashed rgb(0,0,0) 1.0px;background-color: rgb(0,0,255);height: 3.0px;\"/>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Week 3 - Peer-graded Assignment: Segmenting and Clustering Neighborhoods in Toronto", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<hr style=\"border: dashed rgb(0,0,0) 1.0px;background-color: rgb(0,0,0);height: 1.0px;\"/>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Part (1) - Build code to scrape Wikipedia page, obtain the data in the table of postal codes and to transform the data into a pandas dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "For this assignment, you will be required to explore and cluster the neighborhoods in Toronto.\nStart by creating a new Notebook for this assignment.\nUse the Notebook to build the code to scrape the following Wikipedia page, https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M, in order to obtain the data that is in the table of postal codes and to transform the data into a pandas dataframe", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Clear the output\nfrom IPython.display import clear_output\n\n# import the library we use to open URLs\nimport urllib.request\n\n# import the BeautifulSoup library so we can parse HTML and XML documents\nfrom bs4 import BeautifulSoup\n\n# import pandas\nimport pandas as pd", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# specify which URL/web page we are going to be scraping\nurl_wiki = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\n# open the url using urllib.request and put the HTML into the page variable\npage_wiki = urllib.request.urlopen(url_wiki)\n# parse the HTML from our URL into the BeautifulSoup parse tree format\nbs_wiki = BeautifulSoup(page_wiki, \"lxml\")\n\n# use the 'find_all' function to bring back all instances of the 'table' tag in the HTML and store in 'all_tables' variable\ntables_wiki=bs_wiki.find_all(\"table\")", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Get the Required table\ntable_Pcodes=bs_wiki.find('table', class_='wikitable sortable')\n\n# Lists to hold data\nPostalCode=[]\nBorough=[]\nNeighborhood=[]\n\n# Loop & ignore Borough = 'Not assigned'\nfor row in table_Pcodes.findAll('tr'):\n    cells=row.findAll('td')\n    if len(cells) > 0 :\n        # Only process the cells that have an assigned borough. Ignore cells with a borough that is Not assigned.\n        if cells[1].text.strip() != 'Not assigned':\n            PostalCode.append(cells[0].text.strip())\n            Borough.append(cells[1].text.strip())\n            # If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough\n            if cells[2].text.strip() == 'Not assigned':\n                Neighborhood.append(cells[1].text.strip())\n            else:\n                Neighborhood.append(cells[2].text.strip())\n\n# Create dataframe to hold data        \ndf_wiki=pd.DataFrame(PostalCode,columns=['PostalCode'])\ndf_wiki['Borough']=Borough\ndf_wiki['Neighborhood']=Neighborhood\n\n# show data shape\nprint (df_wiki.shape)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Group Values based on the Postal Code\ndf_Pcodes = df_wiki.groupby(['PostalCode','Borough'])['Neighborhood'].apply(', '.join).reset_index()\ndf_Pcodes = df_Pcodes.sort_values(by ='Neighborhood' )\ndf_Pcodes.head(10)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# show data shape\nprint (df_Pcodes.shape)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Display Results same as required in submission", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# create a new dataframe\ncolumn_names = [\"PostalCode\", \"Borough\", \"Neighborhood\"]\ndf_forDisplay = pd.DataFrame(columns=column_names)\n\n# Displayed list in assignment\nPcodes_list = [\"M5G\", \"M2H\", \"M4B\", \"M1J\", \"M4G\", \"M4M\", \"M1R\", \"M9V\", \"M9L\", \"M5V\", \"M1B\", \"M5A\"]\nfor postcode in Pcodes_list:\n    df_forDisplay = df_forDisplay.append(df_Pcodes[df_Pcodes[\"PostalCode\"]==postcode], ignore_index=True)\n    \ndf_forDisplay", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "<hr style=\"border: dashed rgb(0,0,0) 1.0px;background-color: rgb(0,0,0);height: 1.0px;\"/>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Part (2) - Build code to get the latitude and the longitude coordinates of each neighborhood", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#### Option (1) : Using ArcGIS Geocoder rather than Google", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Now that you have built a dataframe of the postal code of each neighborhood along with the borough name and neighborhood name, in order to utilize the Foursquare location data, we need to get the latitude and the longitude coordinates of each neighborhood. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Check geocoder\ntry:\n    import pgeocode\n    print ('Postal Geocoder available')\nexcept ImportError:\n    # installing geocoder\n    print ('Installing Postal Geocoder')\n    !pip install geocoder\n    clear_output()\n    print ('Postal Geocoder Installed')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "import geocoder # convert an address into latitude and longitude values", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Lists to hold data\nLatitude=[]\nLongitude=[]\n\n# Loop & Get coord for postal codes using ArcGIS Geocoder\nfor i in range(0,len(df_Pcodes)):\n    address = df_Pcodes['PostalCode'].iloc[i] + ', canada'\n    g= geocoder.arcgis(address)\n    Latitude.append(g.lat)\n    Longitude.append(g.lng)\n    \n# Create new dataframe to hold coord\ndf_Coords=df_Pcodes.copy()\ndf_Coords['Latitude']=Latitude\ndf_Coords['Longitude']=Longitude\n\ndf_Coords.head(10)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# show data shape\nprint (df_Coords.shape)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Alternative option (Note: Reading from file as geocoder failed)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Given that this package can be very unreliable, in case you are not able to get the geographical coordinates of the neighborhoods using the Geocoder package, here is a link to a csv file that has the geographical coordinates of each postal code: http://cocl.us/Geospatial_data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Lets download the dataset (-q )\n!wget -q -O Geospatial_Coordinates.csv https://cocl.us/Geospatial_data/Geospatial_Coordinates.csv\nprint('Data downloaded!')\n\n# Load Data From CSV File  \ndf_csv = pd.read_csv('Geospatial_Coordinates.csv')\ndf_csv.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# Get the Long & Lat from the csv file and append it to main dataframe\ndf_final = pd.merge(df_Pcodes, df_csv, how='inner', left_on = 'PostalCode', right_on = 'Postal Code')\n\ndf_final.drop(['Postal Code'], axis = 1,inplace=True)\ndf_final.head(10)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Display Results same as required in submission", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# create a new dataframe\ncolumn_names = [\"PostalCode\", \"Borough\", \"Neighborhood\"]\ndf_forDisplay = pd.DataFrame(columns=column_names)\n\n# Displayed list in assignment\nPcodes_list = [\"M5G\", \"M2H\", \"M4B\", \"M1J\", \"M4G\", \"M4M\", \"M1R\", \"M9V\", \"M9L\", \"M5V\", \"M1B\", \"M5A\"]\nfor postcode in Pcodes_list:\n    df_forDisplay = df_forDisplay.append(df_final[df_final[\"PostalCode\"]==postcode], ignore_index=True)\n    \ndf_forDisplay", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# show data shape\nprint (df_final.shape)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "<hr style=\"border: dashed rgb(0,0,0) 1.0px;background-color: rgb(0,0,0);height: 1.0px;\"/>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Part (3) - Explore and cluster the neighborhoods in Toronto", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Explore and cluster the neighborhoods in Toronto. You can decide to work with only boroughs that contain the word Toronto and then replicate the same analysis we did to the New York City data. It is up to you. \nJust make sure:\n\n1- to add enough Markdown cells to explain what you decided to do and to report any observations you make. \n\n2- to generate maps to visualize your neighborhoods and how they cluster together. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Checking for Required Packages availability\n\n# Check folium\ntry:\n    import folium\n    print ('folium available')\nexcept ImportError:\n    # installing folium\n    print ('Installing folium')\n    !conda install -c conda-forge folium=0.5.0 --yes\n    !pip install folium\n    clear_output()\n    print ('folium Installed')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# import required libraries\n\n# import folium\nimport folium", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Create a function to draw marker points", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# add markers to map\ndef drawMarkers(df, FldLat, FldLng, FldBorough, FldHood, map_draw):\n    for lat, lng, borough, neighborhood in zip(df[[FldLat]], df[[FldLng]], df[[FldBorough]], df[[FldHood]]):\n        label = '{}, {}'.format(neighborhood, borough)\n        label = folium.Popup(label, parse_html=True)\n        folium.CircleMarker(\n            [lat, lng],\n            radius=3,\n            popup=label,\n            color='blue',\n            fill=True,\n            fill_color='#3186cc',\n            fill_opacity=0.7,\n            parse_html=False).add_to(map_draw)\n    return(map_draw)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Create a function to search venues to all the neighborhoods", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# create a function to search venues to all the neighborhoods\ndef getNearbyVenues(names, latitudes, longitudes, radius=500):\n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### function to sort the venues in descending order", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Display Toronto Map with neighborhoods", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Get the Coord of Toronto\ng= geocoder.arcgis('Toronto, Canada')\n\n# create map of Toronto using latitude and longitude values\nmap_toronto = folium.Map(location=[g.lat, g.lng], zoom_start=10)\n\n# add markers to map\nmap_toronto = drawMarkers(df_final, 'Latitude', 'Longitude', 'Borough', 'Neighborhood', map_toronto)\nmap_toronto", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Filter only boroughs that contain the word Toronto", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Select subset of the data frmae\ndf_simplified=df_final.copy()\ndf_toronto = df_simplified[df_simplified['Borough'].str.contains('Toronto')]\ndf_toronto.shape\n\n# create map of Toronto using latitude and longitude values\nmap_toronto = folium.Map(location=[g.lat, g.lng], zoom_start=10)\n\n# add markers to map\nmap_toronto = drawMarkers(df_toronto, 'Latitude', 'Longitude', 'Borough', 'Neighborhood', map_toronto)\nmap_toronto", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Start using Foursquare API to explore the neighborhoods", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Define Foursquare Credentials and Version\nCLIENT_ID = 'your-client-ID' # your Foursquare ID\nCLIENT_SECRET = 'your-client-secret' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version\nLIMIT = 100\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "# let's get the venues that are within a radius of 500 meters.\ndf_venues = getNearbyVenues(names=df_toronto['Neighborhood'],\n                                   latitudes=df_toronto['Latitude'],\n                                   longitudes=df_toronto['Longitude']\n                                  )\n\n# check the size of the resulting dataframe\nprint(df_venues.shape)\ndf_venues.head()\n\n# check how many venues were returned for each neighborhood\ndf_venues.groupby('Neighborhood').count()\n\n# find out how many unique categories can be curated from all the returned venues\nprint('There are {} uniques categories.'.format(len(df_venues['Venue Category'].unique())))", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Analyze Each Neighborhood", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# one hot encoding\ntoronto_onehot = pd.get_dummies(df_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntoronto_onehot['Neighborhood'] = df_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\ntoronto_onehot = toronto_onehot[fixed_columns]\n\n# check the size of the resulting dataframe\nprint(toronto_onehot.shape)\ntoronto_onehot.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\ntoronto_grouped", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Let's confirm the new size & print each neighborhood along with the top 20 most common venues", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "num_top_venues = 20\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood']\n\nfor ind in np.arange(toronto_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Cluster Neighborhoods", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Run k-means to cluster the neighborhood into 5 clusters.\n\n# set number of clusters\nkclusters = 5\n\ntoronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] ", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Let's create a new dataframe that includes the cluster as well as the top 20 venues for each neighborhood.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\ntoronto_merged = df_toronto\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\ntoronto_merged.head() # check the last columns!", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Finally, let's visualize the resulting clusters", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\n\n# add markers to map      \nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Examine Clusters", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Cluster 1", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Cluster 2", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Cluster 3", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Cluster 4", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 3, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Cluster 5", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 4, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "#### Observation", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "xxxxxxxxxxxxxxxxxxxxxxxx", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}